{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bc453702-ddb2-49b3-9321-489f49d97987",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain\n",
      "  Using cached langchain-0.3.3-py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain) (6.0.2)\n",
      "Collecting SQLAlchemy<3,>=1.4 (from langchain)\n",
      "  Downloading SQLAlchemy-2.0.35-cp312-cp312-win_amd64.whl.metadata (9.9 kB)\n",
      "Collecting aiohttp<4.0.0,>=3.8.3 (from langchain)\n",
      "  Downloading aiohttp-3.10.10-cp312-cp312-win_amd64.whl.metadata (7.8 kB)\n",
      "Collecting langchain-core<0.4.0,>=0.3.10 (from langchain)\n",
      "  Using cached langchain_core-0.3.10-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting langchain-text-splitters<0.4.0,>=0.3.0 (from langchain)\n",
      "  Using cached langchain_text_splitters-0.3.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting langsmith<0.2.0,>=0.1.17 (from langchain)\n",
      "  Using cached langsmith-0.1.135-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.26.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain) (1.26.4)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain) (2.9.2)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain) (2.32.3)\n",
      "Collecting tenacity!=8.4.0,<9.0.0,>=8.1.0 (from langchain)\n",
      "  Downloading tenacity-8.5.0-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting aiohappyeyeballs>=2.3.0 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Downloading aiohappyeyeballs-2.4.3-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Downloading aiosignal-1.3.1-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting attrs>=17.3.0 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Downloading attrs-24.2.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Downloading frozenlist-1.4.1-cp312-cp312-win_amd64.whl.metadata (12 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Downloading multidict-6.1.0-cp312-cp312-win_amd64.whl.metadata (5.1 kB)\n",
      "Collecting yarl<2.0,>=1.12.0 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Downloading yarl-1.15.2-cp312-cp312-win_amd64.whl.metadata (58 kB)\n",
      "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<0.4.0,>=0.3.10->langchain)\n",
      "  Downloading jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\hp\\appdata\\roaming\\python\\python312\\site-packages (from langchain-core<0.4.0,>=0.3.10->langchain) (24.1)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.10->langchain) (4.12.2)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (0.27.2)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.7)\n",
      "Collecting requests-toolbelt<2.0.0,>=1.0.0 (from langsmith<0.2.0,>=0.1.17->langchain)\n",
      "  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.23.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2->langchain) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2->langchain) (3.8)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2->langchain) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2->langchain) (2024.8.30)\n",
      "Collecting greenlet!=0.4.17 (from SQLAlchemy<3,>=1.4->langchain)\n",
      "  Downloading greenlet-3.1.1-cp312-cp312-win_amd64.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: anyio in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (4.6.2.post1)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.0.6)\n",
      "Requirement already satisfied: sniffio in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (0.14.0)\n",
      "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.10->langchain)\n",
      "  Downloading jsonpointer-3.0.0-py2.py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting propcache>=0.2.0 (from yarl<2.0,>=1.12.0->aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Downloading propcache-0.2.0-cp312-cp312-win_amd64.whl.metadata (7.9 kB)\n",
      "Using cached langchain-0.3.3-py3-none-any.whl (1.0 MB)\n",
      "Downloading aiohttp-3.10.10-cp312-cp312-win_amd64.whl (379 kB)\n",
      "Using cached langchain_core-0.3.10-py3-none-any.whl (404 kB)\n",
      "Using cached langchain_text_splitters-0.3.0-py3-none-any.whl (25 kB)\n",
      "Using cached langsmith-0.1.135-py3-none-any.whl (295 kB)\n",
      "Downloading SQLAlchemy-2.0.35-cp312-cp312-win_amd64.whl (2.1 MB)\n",
      "   ---------------------------------------- 0.0/2.1 MB ? eta -:--:--\n",
      "   --------------- ------------------------ 0.8/2.1 MB 3.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.1/2.1 MB 6.1 MB/s eta 0:00:00\n",
      "Downloading tenacity-8.5.0-py3-none-any.whl (28 kB)\n",
      "Downloading aiohappyeyeballs-2.4.3-py3-none-any.whl (14 kB)\n",
      "Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Downloading attrs-24.2.0-py3-none-any.whl (63 kB)\n",
      "Downloading frozenlist-1.4.1-cp312-cp312-win_amd64.whl (50 kB)\n",
      "Downloading greenlet-3.1.1-cp312-cp312-win_amd64.whl (299 kB)\n",
      "Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Downloading multidict-6.1.0-cp312-cp312-win_amd64.whl (28 kB)\n",
      "Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
      "Downloading yarl-1.15.2-cp312-cp312-win_amd64.whl (84 kB)\n",
      "Downloading jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
      "Downloading propcache-0.2.0-cp312-cp312-win_amd64.whl (44 kB)\n",
      "Installing collected packages: tenacity, propcache, multidict, jsonpointer, greenlet, frozenlist, attrs, aiohappyeyeballs, yarl, SQLAlchemy, requests-toolbelt, jsonpatch, aiosignal, langsmith, aiohttp, langchain-core, langchain-text-splitters, langchain\n",
      "  Attempting uninstall: tenacity\n",
      "    Found existing installation: tenacity 9.0.0\n",
      "    Uninstalling tenacity-9.0.0:\n",
      "      Successfully uninstalled tenacity-9.0.0\n",
      "Successfully installed SQLAlchemy-2.0.35 aiohappyeyeballs-2.4.3 aiohttp-3.10.10 aiosignal-1.3.1 attrs-24.2.0 frozenlist-1.4.1 greenlet-3.1.1 jsonpatch-1.33 jsonpointer-3.0.0 langchain-0.3.3 langchain-core-0.3.10 langchain-text-splitters-0.3.0 langsmith-0.1.135 multidict-6.1.0 propcache-0.2.0 requests-toolbelt-1.0.0 tenacity-8.5.0 yarl-1.15.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The script langsmith.exe is installed in 'c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python312\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script langchain-server.exe is installed in 'c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python312\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n"
     ]
    }
   ],
   "source": [
    "pip install langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0b6e9330",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The script distro.exe is installed in 'c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python312\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n"
     ]
    }
   ],
   "source": [
    "pip install -qU langchain-groq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "22b247bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c47afad9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As of my cut-off knowledge in December 2023, here are some recent news related to SpaceX:\n",
      "\n",
      "1. **Starship Update**: SpaceX has been actively working on its Starship program, a next-generation reusable spacecraft designed for long-duration missions to the Moon, Mars, and other destinations in the solar system. In November 2023, SpaceX conducted a successful static fire test of the Starship's Raptor engines.\n",
      "\n",
      "2. **Crew-6 Mission**: In March 2023, SpaceX launched the Crew-6 mission to the International Space Station (ISS), carrying four astronauts to the orbiting laboratory. The mission marked the sixth operational crew rotation flight to the ISS using SpaceX's Crew Dragon spacecraft.\n",
      "\n",
      "3. **Starlink Satellite Constellation**: SpaceX has been expanding its Starlink satellite constellation, which aims to provide global internet connectivity. As of December 2023, the company has launched over 4,500 Starlink satellites into orbit.\n",
      "\n",
      "4. **Lunar Starship**: In November 2023, NASA announced that SpaceX's Starship had been selected as the lunar lander for the agency's Artemis program, which aims to return humans to the Moon by 2025. The contract is worth $2.9 billion.\n",
      "\n",
      "5. **Reusability Milestone**: In December 2023, SpaceX achieved a significant reusability milestone by launching a Falcon 9 rocket booster for the 15th time. The booster, which was used to launch a batch of Starlink satellites, marked a new record for the most launches of a single orbital-class rocket booster.\n",
      "\n",
      "Please note that these updates are based on my cut-off knowledge in December 2023, and there may be more recent developments that I am not aware of.\n"
     ]
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "\n",
    "llm = ChatGroq(\n",
    "    temperature=0, \n",
    "    groq_api_key='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', \n",
    "    model_name=\"llama-3.1-70b-versatile\"\n",
    ")\n",
    "\n",
    "response = llm.invoke(\"Recent news related to SpaceX?\")\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f503a9af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -qU langchain_community beautifulsoup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9f2d43fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sr. Data Scientist, Search Data Science - Job ID: 2698350 | Amazon.jobs\n",
      "Skip to main contentHomeYour job applicationAmazon culture & benefitsDiversity at AmazonLocationsTeamsJob categoriesResourcesInterview tipsDisability accommodationsAbout AmazonFAQ×Sr. Data Scientist, Search Data ScienceJob ID: 2698350 | Amazon.com Services LLCApply nowDESCRIPTIONAmazon is one of the most popular sites in the US. Our product search engine, one of the most heavily used services in the world, indexes billions of products and serves hundreds of millions of customers world-wide.Our team leads the science and analytics efforts for the search page and we own multiple aspects of understanding how we can measure customer satisfaction with our experiences. This include building science based insights and novel metrics to define and track customer focused aspects.We are working on metrics and measurements to better quantify the customer pain points of the search customer experience and in turn reduce friction for the customers. We are looking for a Senior Data Scientist to lead the development and implementation of different metrics and tackle new and uncharted territories for search engines using LLMs.Key job responsibilitiesWe are looking for an experienced Sr. Data Scientist to lead ML and LLM based signals development and data analytics and drive critical product decisions for Amazon Search. In a fast-paced and ambiguous environment, you will perform multiple large, complex, and business critical analyses that will inform product design and business priorities. You will design and build AI based science solutions to allow routine inspection and deep business understanding as the search customer experience is being transformed. You will analyze A/B tests and recommend ways to making them faster and more robust. Keeping a department-wide view, you will focus on the highest priorities and constantly look for scale and automation, while making technical trade-offs between short term and long-term needs. With your drive to deliver results, you will quickly analyze data and understand the current business challenges to assess the feasibility of different science projects as well as help shape the analytics roadmap of the Search Science teams. Your desire to learn and be curious will help us look around corners for improvement opportunities and more efficient metrics development.In this role, you will partner with data engineers, business intelligence engineers, product managers, software engineers, economists, and other scientists.A day in the lifeYou are have expertise in Machine learning and statistical models. You are comfortable with a higher degree of ambiguity, knows when and how to be scrappy, build quick prototypes and proofs of concepts, innate ability to see around corners and know what is coming, define a long-term science vision, and relish the idea of solving problems that haven’t been solved at scale. As part of our journey to learn about our data, some opportunities may be a dead end and you will balancing unknowns with delivering results for our customers. Along the way, you’ll learn a ton, have fun and make a positive impact at scale.About the teamJoining this team, you’ll experience the benefits of working in a dynamic, entrepreneurial environment, while leveraging the resources of Amazon.com (AMZN), Earth's most customer-centric company and one of the world's leading internet companies. We provide a highly customer-centric, and team-oriented environment.BASIC QUALIFICATIONS- 5+ years of data querying languages (e.g. SQL), scripting languages (e.g. Python) or statistical/mathematical software (e.g. R, SAS, Matlab, etc.) experience- 4+ years of data scientist experience- Experience with statistical models e.g. multinomial logistic regressionPREFERRED QUALIFICATIONS- 2+ years of data visualization using AWS QuickSight, Tableau, R Shiny, etc. experience- Experience managing data pipelines- Experience as a leader and mentor on a data science teamAmazon is committed to a diverse and inclusive workplace. Amazon is an equal opportunity employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status. For individuals with disabilities who would like to request an accommodation, please visit https://www.amazon.jobs/en/disability/us.Los Angeles County applicants: Job duties for this position include: work safely and cooperatively with other employees, supervisors, and staff; adhere to standards of excellence despite stressful conditions; communicate effectively and respectfully with employees, supervisors, and staff to ensure exceptional customer service; and follow all federal, state, and local laws and Company policies. Criminal history may have a direct, adverse, and negative relationship with some of the material job duties of this position. These include the duties and responsibilities listed above, as well as the abilities to adhere to company policies, exercise sound judgment, effectively manage stress and work safely and respectfully with others, exhibit trustworthiness and professionalism, and safeguard business operations and the Company’s reputation. Pursuant to the Los Angeles County Fair Chance Ordinance, we will consider for employment qualified applicants with arrest and conviction records.Our compensation reflects the cost of labor across several US geographic markets. The base pay for this position ranges from $143,300/year in our lowest geographic market up to $247,600/year in our highest geographic market. Pay is based on a number of factors including market location and may vary depending on job-related knowledge, skills, and experience. Amazon is a total compensation company. Dependent on the position offered, equity, sign-on payments, and other forms of compensation may be provided as part of a total compensation package, in addition to a full range of medical, financial, and/or other benefits. For more information,  please visit https://www.aboutamazon.com/workplace/employee-benefits. This position will remain posted until filled. Applicants should apply via our internal or external career site.Job detailsUSA, CA, Palo AltoAmazon SearchMachine Learning ScienceShare this jobJOIN US ONFind CareersJob CategoriesTeamsLocationsUS and EU Military recruitingWarehouse and Hourly JobsWorking At AmazonCultureBenefitsAmazon NewsletterDiversity at AmazonOur leadership principlesHelpFAQInterview tipsReview application statusDisability accommodationsEU background checksAmazon is committed to a diverse and inclusive workplace. Amazon is an equal opportunity employer and does not discriminate on the basis of race, national origin, gender, gender identity, sexual orientation, protected veteran status, disability, age, or other legally protected status.Privacy and DataImpressum© 1996-2024, Amazon.com, Inc. or its affiliates\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "\n",
    "loader = WebBaseLoader(\"https://www.amazon.jobs/en/jobs/2698350/sr-data-scientist-search-data-science\")\n",
    "scrap_data = loader.load().pop().page_content\n",
    "print(scrap_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8f1ef0bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```\n",
      "{\n",
      "  \"role\": \"Sr. Data Scientist, Search Data Science\",\n",
      "  \"experience\": {\n",
      "    \"basic\": [\n",
      "      \"5+ years of data querying languages (e.g. SQL), scripting languages (e.g. Python) or statistical/mathematical software (e.g. R, SAS, Matlab, etc.) experience\",\n",
      "      \"4+ years of data scientist experience\",\n",
      "      \"Experience with statistical models e.g. multinomial logistic regression\"\n",
      "    ],\n",
      "    \"preferred\": [\n",
      "      \"2+ years of data visualization using AWS QuickSight, Tableau, R Shiny, etc. experience\",\n",
      "      \"Experience managing data pipelines\",\n",
      "      \"Experience as a leader and mentor on a data science team\"\n",
      "    ]\n",
      "  },\n",
      "  \"skills\": [\n",
      "    \"Machine learning\",\n",
      "    \"Statistical models\",\n",
      "    \"Data querying languages (e.g. SQL)\",\n",
      "    \"Scripting languages (e.g. Python)\",\n",
      "    \"Statistical/mathematical software (e.g. R, SAS, Matlab, etc.)\",\n",
      "    \"Data visualization using AWS QuickSight, Tableau, R Shiny, etc.\"\n",
      "  ],\n",
      "  \"description\": \"Amazon is looking for a Senior Data Scientist to lead the development and implementation of different metrics and tackle new and uncharted territories for search engines using LLMs. The successful candidate will have expertise in Machine learning and statistical models, and will be comfortable with a higher degree of ambiguity. They will be responsible for designing and building AI based science solutions, analyzing A/B tests, and recommending ways to make them faster and more robust.\"\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "prompt_extract = PromptTemplate.from_template(\n",
    "        \"\"\"\n",
    "        ### SCRAPED TEXT FROM WEBSITE:\n",
    "        {scrap_data}\n",
    "        ### INSTRUCTION:\n",
    "        The scraped text is from the career's page of a website.\n",
    "        Your job is to extract the job postings and return them in JSON format containing the \n",
    "        following keys: `role`, `experience`, `skills` and `description`.\n",
    "        Only return the valid JSON.\n",
    "        ### VALID JSON (NO PREAMBLE):    \n",
    "        \"\"\"\n",
    ")\n",
    "\n",
    "chain_extract = prompt_extract | llm \n",
    "res = chain_extract.invoke(input={'scrap_data':scrap_data})\n",
    "print(res.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a8af2cc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(res.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "07e431e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'role': 'Sr. Data Scientist, Search Data Science',\n",
       " 'experience': {'basic': ['5+ years of data querying languages (e.g. SQL), scripting languages (e.g. Python) or statistical/mathematical software (e.g. R, SAS, Matlab, etc.) experience',\n",
       "   '4+ years of data scientist experience',\n",
       "   'Experience with statistical models e.g. multinomial logistic regression'],\n",
       "  'preferred': ['2+ years of data visualization using AWS QuickSight, Tableau, R Shiny, etc. experience',\n",
       "   'Experience managing data pipelines',\n",
       "   'Experience as a leader and mentor on a data science team']},\n",
       " 'skills': ['Machine learning',\n",
       "  'Statistical models',\n",
       "  'Data querying languages (e.g. SQL)',\n",
       "  'Scripting languages (e.g. Python)',\n",
       "  'Statistical/mathematical software (e.g. R, SAS, Matlab, etc.)',\n",
       "  'Data visualization using AWS QuickSight, Tableau, R Shiny, etc.'],\n",
       " 'description': 'Amazon is looking for a Senior Data Scientist to lead the development and implementation of different metrics and tackle new and uncharted territories for search engines using LLMs. The successful candidate will have expertise in Machine learning and statistical models, and will be comfortable with a higher degree of ambiguity. They will be responsible for designing and building AI based science solutions, analyzing A/B tests, and recommending ways to make them faster and more robust.'}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "\n",
    "json_parser = JsonOutputParser()\n",
    "json_res = json_parser.parse(res.content)\n",
    "json_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c76ea2fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(json_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8d2d087d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openpyxl in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (3.1.5)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: et-xmlfile in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from openpyxl) (1.1.0)\n"
     ]
    }
   ],
   "source": [
    "pip install openpyxl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7509b1ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Skills</th>\n",
       "      <th>Portfolio and Project Links</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>React, Node.js, MongoDB</td>\n",
       "      <td>https://example.com/react-portfolio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Angular, .NET, SQL Server</td>\n",
       "      <td>https://example.com/angular-portfolio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Vue.js, Ruby on Rails, PostgreSQL</td>\n",
       "      <td>https://example.com/vue-portfolio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Python, Django, MySQL</td>\n",
       "      <td>https://example.com/python-portfolio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Java, Spring Boot, Oracle</td>\n",
       "      <td>https://example.com/java-portfolio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>PHP, Laravel, MariaDB</td>\n",
       "      <td>https://example.com/php-portfolio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Flutter, Firebase, Firestore</td>\n",
       "      <td>https://example.com/flutter-portfolio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Kotlin, Android, SQLite</td>\n",
       "      <td>https://example.com/kotlin-portfolio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Swift, iOS, CoreData</td>\n",
       "      <td>https://example.com/swift-portfolio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>C#, ASP.NET, Azure SQL</td>\n",
       "      <td>https://example.com/csharp-portfolio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Golang, Gin, MongoDB</td>\n",
       "      <td>https://example.com/golang-portfolio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Elixir, Phoenix, PostgreSQL</td>\n",
       "      <td>https://example.com/elixir-portfolio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Scala, Play Framework, Cassandra</td>\n",
       "      <td>https://example.com/scala-portfolio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>TypeScript, Express.js, DynamoDB</td>\n",
       "      <td>https://example.com/typescript-portfolio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Rust, Rocket, SQLite</td>\n",
       "      <td>https://example.com/rust-portfolio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Perl, Dancer2, MySQL</td>\n",
       "      <td>https://example.com/perl-portfolio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>C++, Qt, PostgreSQL</td>\n",
       "      <td>https://example.com/cplusplus-portfolio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>R, Shiny, SQLite</td>\n",
       "      <td>https://example.com/r-portfolio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Julia, Genie, MongoDB</td>\n",
       "      <td>https://example.com/julia-portfolio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Ruby, Sinatra, MySQL</td>\n",
       "      <td>https://example.com/ruby-portfolio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Erlang, Cowboy, PostgreSQL</td>\n",
       "      <td>https://example.com/erlang-portfolio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Svelte, Node.js, Firebase</td>\n",
       "      <td>https://example.com/svelte-portfolio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>ASP.NET Core, Azure, Cosmos DB</td>\n",
       "      <td>https://example.com/aspnetcore-portfolio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Next.js, Vercel, MongoDB</td>\n",
       "      <td>https://example.com/nextjs-portfolio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Nuxt.js, Strapi, PostgreSQL</td>\n",
       "      <td>https://example.com/nuxtjs-portfolio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>TensorFlow, Flask, SQLite</td>\n",
       "      <td>https://example.com/tensorflow-portfolio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>PyTorch, FastAPI, PostgreSQL</td>\n",
       "      <td>https://example.com/pytorch-portfolio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Objective-C, Cocoa, SQLite</td>\n",
       "      <td>https://example.com/objectivec-portfolio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>ColdFusion, Fusebox, MySQL</td>\n",
       "      <td>https://example.com/coldfusion-portfolio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Clojure, Pedestal, MongoDB</td>\n",
       "      <td>https://example.com/clojure-portfolio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>ML Engineer, PyTorch, TensorFlow</td>\n",
       "      <td>https://example.com/ml-portfolio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>DL Researcher, Keras, TensorFlow</td>\n",
       "      <td>https://example.com/dl-portfolio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>AI Engineer, OpenAI, LangChain</td>\n",
       "      <td>https://example.com/ai-portfolio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Software Engineer, Java, Kubernetes</td>\n",
       "      <td>https://example.com/se-portfolio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Data Analyst, Python, Power BI</td>\n",
       "      <td>https://example.com/da-portfolio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Data Scientist, R, SQL</td>\n",
       "      <td>https://example.com/ds-portfolio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Big Data Engineer, Hadoop, Spark</td>\n",
       "      <td>https://example.com/bd-portfolio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>NLP Specialist, Hugging Face, BERT</td>\n",
       "      <td>https://example.com/nlp-portfolio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Computer Vision Engineer, OpenCV, YOLO</td>\n",
       "      <td>https://example.com/cv-portfolio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Recommender Systems, Matrix Factorization, PyT...</td>\n",
       "      <td>https://example.com/rs-portfolio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Reinforcement Learning, Stable Baselines, Gym</td>\n",
       "      <td>https://example.com/rl-portfolio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>MLOps Engineer, Kubeflow, Docker</td>\n",
       "      <td>https://example.com/mlops-portfolio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Data Engineer, Apache Kafka, SQL</td>\n",
       "      <td>https://example.com/de-portfolio</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Skills  \\\n",
       "0                             React, Node.js, MongoDB   \n",
       "1                           Angular, .NET, SQL Server   \n",
       "2                   Vue.js, Ruby on Rails, PostgreSQL   \n",
       "3                               Python, Django, MySQL   \n",
       "4                           Java, Spring Boot, Oracle   \n",
       "5                               PHP, Laravel, MariaDB   \n",
       "6                        Flutter, Firebase, Firestore   \n",
       "7                             Kotlin, Android, SQLite   \n",
       "8                                Swift, iOS, CoreData   \n",
       "9                              C#, ASP.NET, Azure SQL   \n",
       "10                               Golang, Gin, MongoDB   \n",
       "11                        Elixir, Phoenix, PostgreSQL   \n",
       "12                   Scala, Play Framework, Cassandra   \n",
       "13                   TypeScript, Express.js, DynamoDB   \n",
       "14                               Rust, Rocket, SQLite   \n",
       "15                               Perl, Dancer2, MySQL   \n",
       "16                                C++, Qt, PostgreSQL   \n",
       "17                                   R, Shiny, SQLite   \n",
       "18                              Julia, Genie, MongoDB   \n",
       "19                               Ruby, Sinatra, MySQL   \n",
       "20                         Erlang, Cowboy, PostgreSQL   \n",
       "21                          Svelte, Node.js, Firebase   \n",
       "22                     ASP.NET Core, Azure, Cosmos DB   \n",
       "23                           Next.js, Vercel, MongoDB   \n",
       "24                        Nuxt.js, Strapi, PostgreSQL   \n",
       "25                          TensorFlow, Flask, SQLite   \n",
       "26                       PyTorch, FastAPI, PostgreSQL   \n",
       "27                         Objective-C, Cocoa, SQLite   \n",
       "28                         ColdFusion, Fusebox, MySQL   \n",
       "29                         Clojure, Pedestal, MongoDB   \n",
       "30                   ML Engineer, PyTorch, TensorFlow   \n",
       "31                   DL Researcher, Keras, TensorFlow   \n",
       "32                     AI Engineer, OpenAI, LangChain   \n",
       "33                Software Engineer, Java, Kubernetes   \n",
       "34                     Data Analyst, Python, Power BI   \n",
       "35                             Data Scientist, R, SQL   \n",
       "36                   Big Data Engineer, Hadoop, Spark   \n",
       "37                 NLP Specialist, Hugging Face, BERT   \n",
       "38             Computer Vision Engineer, OpenCV, YOLO   \n",
       "39  Recommender Systems, Matrix Factorization, PyT...   \n",
       "40      Reinforcement Learning, Stable Baselines, Gym   \n",
       "41                   MLOps Engineer, Kubeflow, Docker   \n",
       "42                   Data Engineer, Apache Kafka, SQL   \n",
       "\n",
       "                 Portfolio and Project Links  \n",
       "0        https://example.com/react-portfolio  \n",
       "1      https://example.com/angular-portfolio  \n",
       "2          https://example.com/vue-portfolio  \n",
       "3       https://example.com/python-portfolio  \n",
       "4         https://example.com/java-portfolio  \n",
       "5          https://example.com/php-portfolio  \n",
       "6      https://example.com/flutter-portfolio  \n",
       "7       https://example.com/kotlin-portfolio  \n",
       "8        https://example.com/swift-portfolio  \n",
       "9       https://example.com/csharp-portfolio  \n",
       "10      https://example.com/golang-portfolio  \n",
       "11      https://example.com/elixir-portfolio  \n",
       "12       https://example.com/scala-portfolio  \n",
       "13  https://example.com/typescript-portfolio  \n",
       "14        https://example.com/rust-portfolio  \n",
       "15        https://example.com/perl-portfolio  \n",
       "16   https://example.com/cplusplus-portfolio  \n",
       "17           https://example.com/r-portfolio  \n",
       "18       https://example.com/julia-portfolio  \n",
       "19        https://example.com/ruby-portfolio  \n",
       "20      https://example.com/erlang-portfolio  \n",
       "21      https://example.com/svelte-portfolio  \n",
       "22  https://example.com/aspnetcore-portfolio  \n",
       "23      https://example.com/nextjs-portfolio  \n",
       "24      https://example.com/nuxtjs-portfolio  \n",
       "25  https://example.com/tensorflow-portfolio  \n",
       "26     https://example.com/pytorch-portfolio  \n",
       "27  https://example.com/objectivec-portfolio  \n",
       "28  https://example.com/coldfusion-portfolio  \n",
       "29     https://example.com/clojure-portfolio  \n",
       "30          https://example.com/ml-portfolio  \n",
       "31          https://example.com/dl-portfolio  \n",
       "32          https://example.com/ai-portfolio  \n",
       "33          https://example.com/se-portfolio  \n",
       "34          https://example.com/da-portfolio  \n",
       "35          https://example.com/ds-portfolio  \n",
       "36          https://example.com/bd-portfolio  \n",
       "37         https://example.com/nlp-portfolio  \n",
       "38          https://example.com/cv-portfolio  \n",
       "39          https://example.com/rs-portfolio  \n",
       "40          https://example.com/rl-portfolio  \n",
       "41       https://example.com/mlops-portfolio  \n",
       "42          https://example.com/de-portfolio  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_excel(\"skills_portfolio_links.xlsx\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f5312d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "import chromadb\n",
    "\n",
    "client = chromadb.PersistentClient('vectorstore')\n",
    "collection = client.get_or_create_collection(name=\"portfolio\")\n",
    "\n",
    "if not collection.count():\n",
    "    for _, row in df.iterrows():\n",
    "        collection.add(documents=row[\"Skills\"],\n",
    "                       metadatas={\"links\": row[\"Portfolio and Project Links\"]},\n",
    "                       ids=[str(uuid.uuid4())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b165c4bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'links': 'https://example.com/ml-portfolio'},\n",
       "  {'links': 'https://example.com/rl-portfolio'},\n",
       "  {'links': 'https://example.com/ai-portfolio'},\n",
       "  {'links': 'https://example.com/cv-portfolio'},\n",
       "  {'links': 'https://example.com/dl-portfolio'},\n",
       "  {'links': 'https://example.com/ds-portfolio'},\n",
       "  {'links': 'https://example.com/rs-portfolio'},\n",
       "  {'links': 'https://example.com/se-portfolio'},\n",
       "  {'links': 'https://example.com/bd-portfolio'},\n",
       "  {'links': 'https://example.com/de-portfolio'}],\n",
       " [{'links': 'https://example.com/ds-portfolio'},\n",
       "  {'links': 'https://example.com/bd-portfolio'},\n",
       "  {'links': 'https://example.com/de-portfolio'},\n",
       "  {'links': 'https://example.com/da-portfolio'},\n",
       "  {'links': 'https://example.com/se-portfolio'},\n",
       "  {'links': 'https://example.com/cv-portfolio'},\n",
       "  {'links': 'https://example.com/erlang-portfolio'},\n",
       "  {'links': 'https://example.com/dl-portfolio'},\n",
       "  {'links': 'https://example.com/r-portfolio'},\n",
       "  {'links': 'https://example.com/scala-portfolio'}]]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex_links = collection.query(query_texts=[\"Experience in Machine learning\", \"Experience in Data Science\"]).get('metadatas', [])\n",
    "ex_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "41e6be49",
   "metadata": {},
   "outputs": [],
   "source": [
    "job = json_res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "dbafbab2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'role': 'Sr. Data Scientist, Search Data Science',\n",
       " 'experience': {'basic': ['5+ years of data querying languages (e.g. SQL), scripting languages (e.g. Python) or statistical/mathematical software (e.g. R, SAS, Matlab, etc.) experience',\n",
       "   '4+ years of data scientist experience',\n",
       "   'Experience with statistical models e.g. multinomial logistic regression'],\n",
       "  'preferred': ['2+ years of data visualization using AWS QuickSight, Tableau, R Shiny, etc. experience',\n",
       "   'Experience managing data pipelines',\n",
       "   'Experience as a leader and mentor on a data science team']},\n",
       " 'skills': ['Machine learning',\n",
       "  'Statistical models',\n",
       "  'Data querying languages (e.g. SQL)',\n",
       "  'Scripting languages (e.g. Python)',\n",
       "  'Statistical/mathematical software (e.g. R, SAS, Matlab, etc.)',\n",
       "  'Data visualization using AWS QuickSight, Tableau, R Shiny, etc.'],\n",
       " 'description': 'Amazon is looking for a Senior Data Scientist to lead the development and implementation of different metrics and tackle new and uncharted territories for search engines using LLMs. The successful candidate will have expertise in Machine learning and statistical models, and will be comfortable with a higher degree of ambiguity. They will be responsible for designing and building AI based science solutions, analyzing A/B tests, and recommending ways to make them faster and more robust.'}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3ae59068",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Machine learning',\n",
       " 'Statistical models',\n",
       " 'Data querying languages (e.g. SQL)',\n",
       " 'Scripting languages (e.g. Python)',\n",
       " 'Statistical/mathematical software (e.g. R, SAS, Matlab, etc.)',\n",
       " 'Data visualization using AWS QuickSight, Tableau, R Shiny, etc.']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job['skills']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b99d1dfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'links': 'https://example.com/ml-portfolio'},\n",
       "  {'links': 'https://example.com/rl-portfolio'}],\n",
       " [{'links': 'https://example.com/rs-portfolio'},\n",
       "  {'links': 'https://example.com/ds-portfolio'}],\n",
       " [{'links': 'https://example.com/ds-portfolio'},\n",
       "  {'links': 'https://example.com/csharp-portfolio'}],\n",
       " [{'links': 'https://example.com/python-portfolio'},\n",
       "  {'links': 'https://example.com/erlang-portfolio'}],\n",
       " [{'links': 'https://example.com/ds-portfolio'},\n",
       "  {'links': 'https://example.com/da-portfolio'}],\n",
       " [{'links': 'https://example.com/r-portfolio'},\n",
       "  {'links': 'https://example.com/ds-portfolio'}]]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "links = collection.query(query_texts=job['skills'], n_results=2).get('metadatas', [])\n",
    "links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f64a3494",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject: Application for Sr. Data Scientist, Search Data Science Role\n",
      "\n",
      "Dear Hiring Manager,\n",
      "\n",
      "I am writing to express my enthusiasm for the Sr. Data Scientist, Search Data Science position at Amazon. As a Master's student in Data Science at Texas A&M University with three years of experience in data-related roles, I am confident that my skills and expertise align with the requirements of this position.\n",
      "\n",
      "With a strong background in machine learning, statistical models, and data analysis, I am well-equipped to lead the development and implementation of different metrics and tackle new and uncharted territories for search engines using LLMs. My experience in data querying languages (e.g., SQL), scripting languages (e.g., Python), and statistical/mathematical software (e.g., R, SAS, Matlab, etc.) has prepared me to design and build AI-based science solutions.\n",
      "\n",
      "In my previous roles, I have successfully analyzed A/B tests and recommended ways to make them faster and more robust. For instance, in a project where I worked on optimizing a recommendation system using collaborative filtering, I was able to improve the system's accuracy by 25% and reduce the latency by 30%. You can find more details about this project in my machine learning portfolio: https://example.com/ml-portfolio.\n",
      "\n",
      "Additionally, I have experience in data visualization using tools like Tableau and R Shiny. In a project where I worked on visualizing customer behavior, I created interactive dashboards that helped stakeholders gain insights into customer purchasing patterns. You can find more details about this project in my data science portfolio: https://example.com/ds-portfolio.\n",
      "\n",
      "I am particularly drawn to this role because of the opportunity to work on search engines using LLMs. I believe that my skills and experience make me a strong candidate for this position, and I am excited about the prospect of contributing to the development of innovative solutions at Amazon.\n",
      "\n",
      "Thank you for considering my application. I would welcome the opportunity to discuss my qualifications further and explain in greater detail why I am the ideal candidate for this role.\n",
      "\n",
      "Best regards,\n",
      "\n",
      "Kanak\n"
     ]
    }
   ],
   "source": [
    "prompt_email = PromptTemplate.from_template(\n",
    "        \"\"\"\n",
    "        ### JOB DESCRIPTION:\n",
    "        {job_description}\n",
    "        \n",
    "        ### INSTRUCTION:\n",
    "        You are Kanak, a student currently pursuing your Master's of Science in Data Science at Texas A&M University. With three years of experience in data-related roles, you possess a strong skill set in data analysis, machine learning, and data engineering.\n",
    "        Your job is to write a cold email to the hiring manager regarding a job opportunity that aligns with your expertise. In your email, express your enthusiasm for the position and highlight your relevant skills and experience that make you a strong candidate.\n",
    "        Additionally, include examples of past projects or experiences that demonstrate your capabilities in fulfilling the job requirements. \n",
    "        Also add the most relevant ones from the following links to showcase Kanak's portfolio: {list_of_links}\n",
    "        Remember, you are Kanak, a Master's student in Data Science with three years of data experience. \n",
    "        Do not provide a preamble.\n",
    "        ### EMAIL (NO PREAMBLE):\n",
    "        \n",
    "        \"\"\"\n",
    "        )\n",
    "\n",
    "chain_email = prompt_email | llm\n",
    "res = chain_email.invoke({\"job_description\": str(job), \"list_of_links\": links})\n",
    "print(res.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e547a5d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6321abba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
